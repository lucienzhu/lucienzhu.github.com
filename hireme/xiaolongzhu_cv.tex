%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%% Simple LaTeX CV Template %%%%%%%%%%%%%%%%%%%%%%%%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% NOTE: If you find that it says                                     %%
%%                                                                    %%
%%                           1 of ??                                  %%
%%                                                                    %%
%% at the bottom of your first page, this means that the AUX file     %%
%% was not available when you ran LaTeX on this source. Simply RERUN  %%
%% LaTeX to get the ``??'' replaced with the number of the last page  %%
%% of the document. The AUX file will be generated on the first run   %%
%% of LaTeX and used on the second run to fill in all of the          %%
%% references.                                                        %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%%%%% Document Setup %%%%%%%%%%%%%%%%%%%%%%%%%%%%

% Don't like 10pt? Try 11pt or 12pt
\documentclass[10pt]{article}

% This is a helpful package that puts math inside length specifications
\usepackage{calc}

% set main font
\usepackage[scaled=0.92]{helvet}
\renewcommand{\familydefault}{\sfdefault}

% Simpler bibsection for CV sections
% (thanks to natbib for inspiration)
\makeatletter
\newlength{\bibhang}
\setlength{\bibhang}{1.5em}
\newlength{\bibsep}
 {\@listi \global\bibsep\itemsep \global\advance\bibsep by\parsep}
\newenvironment{bibsection}%
        {\vspace{\itemsep}\begin{list}{}{%
       \setlength{\leftmargin}{\bibhang}%
       %\setlength{\itemindent}{-\leftmargin}%
       \setlength{\itemsep}{\bibsep}%
       \setlength{\parsep}{\z@}%
        \setlength{\partopsep}{0pt}%
        \setlength{\topsep}{0pt}}}
        {\end{list}\vspace{\itemsep}}
\makeatother

% Layout: Puts the section titles on left side of page
\reversemarginpar

%
%         PAPER SIZE, PAGE NUMBER, AND DOCUMENT LAYOUT NOTES:
%
% The next \usepackage line changes the layout for CV style section
% headings as marginal notes. It also sets up the paper size as either
% letter or A4. By default, letter was used. If A4 paper is desired,
% comment out the letterpaper lines and uncomment the a4paper lines.
%
% As you can see, the margin widths and section title widths can be
% easily adjusted.
%
% ALSO: Notice that the includefoot option can be commented OUT in order
% to put the PAGE NUMBER *IN* the bottom margin. This will make the
% effective text area larger.
%
% IF YOU WISH TO REMOVE THE ``of LASTPAGE'' next to each page number,
% see the note about the +LP and -LP lines below. Comment out the +LP
% and uncomment the -LP.
%
% IF YOU WISH TO REMOVE PAGE NUMBERS, be sure that the includefoot line
% is uncommented and ALSO uncomment the \pagestyle{empty} a few lines
% below.
%

%% Use these lines for letter-sized paper
\usepackage[paper=letterpaper,
            %includefoot, % Uncomment to put page number above margin
            marginparwidth=1.2in,     % Length of section titles
            marginparsep=.05in,       % Space between titles and text
            margin=1in,               % 1 inch margins
            includemp]{geometry}

%% Use these lines for A4-sized paper
%\usepackage[paper=a4paper,
%            %includefoot, % Uncomment to put page number above margin
%            marginparwidth=30.5mm,    % Length of section titles
%            marginparsep=1.5mm,       % Space between titles and text
%            margin=25mm,              % 25mm margins
%            includemp]{geometry}

%% More layout: Get rid of indenting throughout entire document
\setlength{\parindent}{0in}

%% This gives us fun enumeration environments. compactitem will be nice.
\usepackage{paralist}

%% Reference the last page in the page number
%
% NOTE: comment the +LP line and uncomment the -LP line to have page
%       numbers without the ``of ##'' last page reference)
%
% NOTE: uncomment the \pagestyle{empty} line to get rid of all page
%       numbers (make sure includefoot is commented out above)
%
\usepackage{fancyhdr,lastpage}
\pagestyle{fancy}
%\pagestyle{empty}      % Uncomment this to get rid of page numbers
\fancyhf{}\renewcommand{\headrulewidth}{0pt}
\fancyfootoffset{\marginparsep+\marginparwidth}
\newlength{\footpageshift}
\setlength{\footpageshift}
          {0.5\textwidth+0.5\marginparsep+0.5\marginparwidth-2in}
\lfoot{\hspace{\footpageshift}%
       \parbox{4in}{\, \hfill %
                    \arabic{page} of \protect\pageref*{LastPage} % +LP
%                    \arabic{page}                               % -LP
                    \hfill \,}}

% Finally, give us PDF bookmarks
\usepackage{color,hyperref}
\definecolor{darkblue}{rgb}{0.0,0.0,0.3}
\hypersetup{colorlinks,breaklinks,
            linkcolor=darkblue,urlcolor=darkblue,
            anchorcolor=darkblue,citecolor=darkblue}

%%%%%%%%%%%%%%%%%%%%%%%% End Document Setup %%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%% Helper Commands %%%%%%%%%%%%%%%%%%%%%%%%%%%%

% The title (name) with a horizontal rule under it
%
% Usage: \makeheading{name}
%
% Place at top of document. It should be the first thing.
\newcommand{\makeheading}[1]%
        {\hspace*{-\marginparsep minus \marginparwidth}%
         \begin{minipage}[t]{\textwidth+\marginparwidth+\marginparsep}%
                {\large \bfseries #1}\\[-0.15\baselineskip]%
                 \rule{\columnwidth}{1pt}%
         \end{minipage}}

% The section headings
%
% Usage: \section{section name}
%
% Follow this section IMMEDIATELY with the first line of the section
% text. Do not put whitespace in between. That is, do this:
%
%       \section{My Information}
%       Here is my information.
%
% and NOT this:
%
%       \section{My Information}
%
%       Here is my information.
%
% Otherwise the top of the section header will not line up with the top
% of the section. Of course, using a single comment character (%) on
% empty lines allows for the function of the first example with the
% readability of the second example.
\renewcommand{\section}[2]%
        {\pagebreak[2]\vspace{1.3\baselineskip}%
         \phantomsection\addcontentsline{toc}{section}{#1}%
         \hspace{0in}%
         \marginpar{
         \raggedright \scshape #1}#2}

% An itemize-style list with lots of space between items
\newenvironment{outerlist}[1][\enskip\textbullet]%
        {\begin{itemize}[#1]}{\end{itemize}%
         \vspace{-.6\baselineskip}}

% An environment IDENTICAL to outerlist that has better pre-list spacing
% when used as the first thing in a \section
\newenvironment{lonelist}[1][\enskip\textbullet]%
        {\vspace{-\baselineskip}\begin{list}{#1}{%
        \setlength{\partopsep}{0pt}%
        \setlength{\topsep}{0pt}}}
        {\end{list}\vspace{-.6\baselineskip}}

% An itemize-style list with little space between items
\newenvironment{innerlist}[1][\enskip\textbullet]%
        {\begin{compactitem}[#1]}{\end{compactitem}}

% An environment IDENTICAL to innerlist that has better pre-list spacing
% when used as the first thing in a \section
\newenvironment{loneinnerlist}[1][\enskip\textbullet]%
        {\vspace{-\baselineskip}\begin{compactitem}[#1]}
        {\end{compactitem}\vspace{-.6\baselineskip}}

% To add some paragraph space between lines.
% This also tells LaTeX to preferably break a page on one of these gaps
% if there is a needed pagebreak nearby.
\newcommand{\blankline}{\quad\pagebreak[2]}

% Uses hyperref to link DOI
\newcommand\doilink[1]{\href{http://dx.doi.org/#1}{#1}}
\newcommand\doi[1]{doi:\doilink{#1}}

% For \url{SOME_URL}, links SOME_URL to the url SOME_URL
\providecommand*\url[1]{\href{#1}{#1}}
% Same as above, but pretty-prints SOME_URL in teletype fixed-width font
\renewcommand*\url[1]{\href{#1}{\texttt{#1}}}

% For \email{ADDRESS}, links ADDRESS to the url mailto:ADDRESS
\providecommand*\email[1]{\href{mailto:#1}{#1}}
% Same as above, but pretty-prints ADDRESS in teletype fixed-width font
%\renewcommand*\email[1]{\href{mailto:#1}{\texttt{#1}}}

%%%%%%%%%%%%%%%%%%%%%%%% End Helper Commands %%%%%%%%%%%%%%%%%%%%%%%%%%%

%%%%%%%%%%%%%%%%%%%%%%%%% Begin CV Document %%%%%%%%%%%%%%%%%%%%%%%%%%%%

\begin{document}
\makeheading{\huge{Xiaolong~ZHU}}

\section{Contact Information}
%
% NOTE: Mind where the & separators and \\ breaks are in the following
%       table.
%
% ALSO: \rcollength is the width of the right column of the table
%       (adjust it to your liking; default is 1.85in).
%
\newlength{\rcollength}\setlength{\rcollength}{2.15in}%
%
\begin{tabular}[t]{@{}p{\textwidth-\rcollength}p{\rcollength}}
Parametrix.ai
     & \textit{Mobile:} \texttt{+86-14714930403} \\%
     2004, Bld 9B, 
     & \textit{Skype:} \texttt{lucienzhu@hotmail.com} \\
	 Shenzhenwan Science \& Tech Ecological Garden
     & \textit{E-mail:} \texttt{lucienxlzhu@gmail.com}\\
Nanshan, Shenzhen
     & \textit{WWW:}
\href{http://xiaolongzhu.org}{\texttt{xiaolongzhu.org}}\\
\end{tabular}

%\section{Citizenship}
%
%USA

%%%%%%%%%%%%%%%%%%%%% RESEARCH INTERESTS %%%%%%%%%%%%%%%%%%%%%%%%

\section{Research Interests}
%
\textbf{AI and Games}, including \emph{Bots}, \emph{AI NPC}, \emph{Generative AI}, \emph{Agents};

\textbf{Computer Vision}, including \emph{Image Classification}, \emph{Object Detection}, \emph{Semantic Labelling}, \emph{Landmark Localization}, \emph{Neural Fields};

\textbf{Machine Learning}, including \emph{Random Forest}, \emph{Support Vector Machines}, \emph{Deep Learning}, \emph{Reinforcement Learning}, \emph{Diffusion Models}, \emph{Foundation Models};

\textbf{Edge Computing}, including \emph{Image Processing}, \emph{CPU/GPU/NPU Neural Network Inference}, \emph{Heterogeneous Computing};

\textbf{Human-Computer Interaction}, including \emph{User Study}, \emph{Prototyping}, \emph{Gestural Interface}.


%%%%%%%%%%%%%%%%%%%%% EDUCATION %%%%%%%%%%%%%%%%%%%%%%%%
\section{Education}
%
\href{http://www.hku.hk/}{\textbf{The University of Hong Kong}}, \hfill
Hong Kong SAR, China
\begin{outerlist}

\item[] Ph.D.,
        \href{http://www.cs.hku.hk/}
             {\emph{Computer Science}},
             \hfill \textbf{September 2010 - January 2016}
        \begin{innerlist}
        %\item Thesis Topic: \emph{Design and Analysis of Optimal
        %    Task-Processing Agents}
        %\item Thesis Proposal: \emph{Cooperative Task Processing}
        %\item Candidacy Exam: \emph{Research
        \item Thesis Title: Hand Detection and Hand Shape and Posture Analysis in Images.
        \item Advisor:
              \href{http://i.cs.hku.hk/~kykwong/}
                   {Dr. Kenneth K. Y. Wong}
        %\item Area of Study: Sketch-based Interface for Computer Vision
        \end{innerlist}
\end{outerlist}

\blankline

%
\href{http://www.hku.hk/}{\textbf{Peking University}}, \hfill
Beijing, China
\begin{outerlist}
\item[] B.S.,
        \href{http://eecs.pku.edu.cn/}
             {\emph{Intelligence Science and Technology}} \hfill \textbf{September 2006 - June 2010}
        \begin{innerlist}
        \item Thesis Title:  Segmentation and Classification of Range Image.
        \item \emph{Excellent Undergraduate Thesis Award}.
        \item Advisor:  \href{http://www.cis.pku.edu.cn/faculty/vision/zhaohj/index-e.htm} {Dr. Huijing Zhao}
        \end{innerlist}

\end{outerlist}


%%%%%%%%%%%%%%%%%%%%% PROFESSIONAL EXPERIENCE %%%%%%%%%%%%%%%%%%%%%%%%

\section{Experience}
%% one entry
\href{https://chaocanshu.cn/}{\textbf{Parametrix.ai}}, \href{https://www.cbinsights.com/company/hyperparameter-technology}{Tech Unicorn on Gaming AI}\hfill
Shenzhen, China
\begin{outerlist}
  \item[] \textit{Vice President}%
  \hfill \textbf{Mar 2019 - Present}
  \begin{innerlist}
    \item Business solutions and AI innovations, \textit{e.g.}, Bots, NPCs and Generative AI;
    \item Platforms and algorithms design, \textit{e.g.}, Distributed RL, Diffusion Models and Agents;
    \item Brands and UR, \textit{e.g.}, NeuralMMO/Lux Competitions, MIT/THU/PKU Collaboration;
    \item Talent recruitment. Interviewed 500+ candidates of AI/Game/Frontend/Backend/Art/Design background;.
   \end{innerlist}
\end{outerlist}

\blankline

%% one entry
\href{http://hr.qq.com/}{\textbf{Tencent TEG}}, \hfill
Shenzhen, China
\begin{outerlist}
  \item[] \textit{Senior R\&D Engineer, Tech Lead}%
  \hfill \textbf{Aug 2016 - Mar 2019}
  \begin{innerlist}
    \item Led to deploy real-time face detection, landmarks and deformation on mobile phones;
    \item Developed and deployed real-time human pose estimation on iOS/Android phones;
    \item Helped to develop reinforcement learning for board game AI;
    \item Deployed real-time live video style transfer on iOS/Android phones;
		\item Developed an algorithm for real-time video style transfer;
		\item Developed several prototypes for AI Lab Vision Team.
	\end{innerlist}

	\item[] \textit{R\&D Engineer}%
	\hfill \textbf{Jul 2015 - Aug 2016}
	\begin{innerlist}
		\item Implemented CTC model for end-to-end speech recognition, collaborating with WeChat Speech Team;
		\item Worked on prototyping news recommendation using DNN model;
		\item Implemented a prototype of service robot based on ROS/Turtlebot.
	\end{innerlist}
\end{outerlist}

\blankline

%% one entry
\href{http://www.lenovo.com}{\textbf{Lenovo IVC Lab}}, \hfill
Hong Kong SAR, China
\begin{outerlist}

\item[] \textit{Research Intern}%
        \hfill \textbf{June 2013 - August 2013}
\begin{innerlist}
\item Innovated new ways for image searching.
\item Designed a prototype of touch-based image retrieval system and demonstrated it to CTO.
\end{innerlist}
\end{outerlist}

\blankline

%% one entry
\href{http://research.microsoft.com/hci}{\textbf{Microsoft Research Asia}}, \hfill
Beijing, China
\begin{outerlist}

\item[] \textit{Research Intern}%
        \hfill \textbf{June 2012 - September 2012}
\begin{innerlist}
\item Learned HCI workflow of problem solving;
\item Designed visual feedback for in-air gesture recognition.
\end{innerlist}
\end{outerlist}

\blankline

%% one entry
\href{http://www.youdao.com/}{\textbf{Youdao.com}}, \hfill
Beijing, China
\begin{outerlist}

\item[] \textit{Software Engineer Intern}%
        \hfill \textbf{June 2010 - August 2010}
\begin{innerlist}
\item Coded web front-end of a \href{http://bafang.163.com}{Location-based Social Network Service};
\item Cooperated with web designer.
\end{innerlist}
\end{outerlist}

\blankline

%% one entry
\href{http://www.pku.edu.cn}{\textbf{Peking University}}, \hfill
Beijing, China
\begin{outerlist}

\item[] \textit{Undergraduate Research Assistant}%
        \hfill \textbf{September 2008 - June 2010}
\begin{innerlist}
\item Participated in the \href{http://www.poss.pku.edu.cn/}{\emph{POSS}} project, in
        \href{http://www.cis.pku.edu.cn/vision/3DVCR/3DVCR_E.html}{3D VCR Lab};
\item Analyzed range data using computer vision methods.
\end{innerlist}

\end{outerlist}


%%%%%%%%%%%%%%%%%%%%% TEACHING EXPERIENCE %%%%%%%%%%%%%%%%%%%%%%%%

\section{Teaching}
\href{https://www.sigs.tsinghua.edu.cn/en/}{\textbf{Tsinghua Shenzhen International Graduate School}}, \hfill
Shenzhen, China
\begin{outerlist}
\item[] \textit{Guest Teacher}%
        \hfill \textbf{September 2021 - Aug 2024}
        \begin{innerlist}
        \item Guest speaker in Frontiers of AI Technology and Industrial Applications, 2022
        \item Guest speaker in Frontiers of AI Technology and Industrial Applications, 2021
        \end{innerlist}
\end{outerlist}

\blankline

\href{http://www.hku.hk}{\textbf{The University of Hong Kong}}, \hfill
Hong Kong SAR, China
\begin{outerlist}
\item[] \textit{Teaching Assistant}%
        \hfill \textbf{September 2010 - May 2014}
        \begin{innerlist}
        \item Assisted \href{http://i.cs.hku.hk/~kykwong}{Dr. Kenneth K.Y. Wong} in \href{http://www.cs.hku.hk/programme/beng-cs/course-description.jsp}
                            {Computer Vision};
        \item Assisted \href{http://i.cs.hku.hk/~kykwong}{Dr. Kenneth K.Y. Wong} in \href{http://i.cs.hku.hk/~engg1111c}
                            {Computer Programming and Applications};
        \item Assisted \href{http://i.cs.hku.hk/~ykchoi}{Dr. Loretta Yi-King Choi} in \href{http://i.cs.hku.hk/~com7801}
                            {Topic in Computer Science: Visual Analysis}.
        \item Assisted \href{http://i.cs.hku.hk/~kykwong}{Dr. Kenneth K.Y. Wong} in \href{http://i.cs.hku.hk/~csis0317}
                            {Computer Vision};
        \item Assisted \href{http://i.cs.hku.hk/~ckchui}{Dr. Chun Kit Chui} in \href{http://i.cs.hku.hk/~eng1002b}
				 {Computer Programming and Applications};
        \item Assisted \href{http://i.cs.hku.hk/~kykwong}{Dr. Kenneth K.Y. Wong} in \href{http://i.cs.hku.hk/~eng1002b}
                            {Computer Programming and Applications};
        \end{innerlist}
\end{outerlist}

%%%%%%%%%%%%%%%%%%%%% TALKS %%%%%%%%%%%%%%%%%%%%%%%%

\section{Talks}
$\bullet$ Algorithms and Applications of Massive Agents. Synced AI Annual Talks. in \textit{Chinese}. 2023; 

$\bullet$ How I teach AI to master the competition. 36Kr Documentary. in \textit{Chinese}. 2022; 
    
$\bullet$ Mobile AI Development on Arm Platform. Arm Developers Global Summit. in \textit{Chinese}. 2018;

$\bullet$ Deploying AI on Mobile. Tencent HKU recruitment talk. 2018;

$\bullet$ Human Pose Estimation on Mobile. Tencent TLC. in \textit{Chinese}. 2018;

$\bullet$ Panelist for LF DL session and Deep Learning Session. LC3 China. 2018;

$\bullet$ Learning Game of Go. Tencent AI Lab Academic Forum. in \textit{Chinese}. 2018;

%%%%%%%%%%%%%%%%%%%%% HONOR AND AWARDS %%%%%%%%%%%%%%%%%%%%%%%%

\section{Awards}
$\bullet$ Overseas High-Caliber Personnel (Level C) in Shenzhen, 2017-2023;

$\bullet$ Tencent Excellent R\&D of the Year 2018, 2018;

$\bullet$ Tencent Technology Breakthrough of the Year 2017, 2017;

$\bullet$ Studentship of the University of Hong Kong, 2010-2014;

$\bullet$ Top 10 Undergraduate Thesis, School of EECS in Peking University, 2010;

$\bullet$ Wusi Scholarship in Peking University, 2009;

$\bullet$ Outstanding Volunteer in Beijing 2008 Olympic Games, 2008;

$\bullet$ First Class Honor in China Physics Olympic Games, Gansu, 2006.

%%%%%%%%%%%%%%%%%%%%% TECHNICAL SKILLS %%%%%%%%%%%%%%%%%%%%%%%%

\section{Technical Skills}
$\bullet$ Programming in: \texttt{Python}, \texttt{C/C++}, \texttt{Matlab}, \texttt{JavaScript/HTML/CSS};

$\bullet$ Basic Experience in: \texttt{Objective-C}, \texttt{Processing}, \texttt{UNIX Shell scripting};

$\bullet$ Native Mandarin speaker, fluent in English, very little Japanese and Cantonese;

$\bullet$ Operating Systems: Windows, Mac OS X.

%%%%%%%%%%%%%%%%%%%%% SOCIAL ACTIVITIES %%%%%%%%%%%%%%%%%%%%%%%%

\section{Social Activities}
$\bullet$ TAC Member of LF Deep Learning Foundation, 2018-2019;

$\bullet$ Member of Tencent Open Source Working Group, 2018-2019;

$\bullet$ Co-founder of Tech Club of Tencent TEG, 2015-2016;

$\bullet$ Member of \href{http://intraweb.hku.hk/local/its/itc.html}{Information Technology Committee}, The University of Hong Kong, 2012-2014;

$\bullet$ IT Officer of \href{http://www.pgsa.hku.hk/}{Postgraduate Association (PGSA)} in
 \href{http://www.hku.hk/}{The University of Hong Kong}, 2011-2013;

$\bullet$ Volunteer as Media Assistant for Journalists in \href{http://en.wikipedia.org/wiki/2008_Summer_Olympics}{Games of the XXIX Olympiad}, 2008.

\section{Hobbies}
Board Games, Hiking, Indoor Climbing.



%%%%%%%%%%%%%%%%%%%%% PUBLICATION %%%%%%%%%%%%%%%%%%%%%%%%

\section{Publications}
[Refereed Conference Papers]

\begin{bibsection}
    \item[17.]Joseph Suarez, David Bloomin, Kyoung Whan Choe, Hao Xiang Li, Ryan Sullivan, Nishaanth Kanna, Daniel Scott, Rose Shuman, Herbie Bradley, Louis Castricato, Phillip Isola, Chenghui Yu, Yuhao Jiang, Qimai Li, Jiaxin Chen, \textbf{Xiaolong Zhu}. ``Neural MMO 2.0: A Massively Multi-task Addition to Massively Multi-agent Learning." \emph{Advances in Neural Information Processing Systems (NeurIPS)}, 2024.

    \item[16.]Kai Yang, Jian Tao, Jiafei Lyu, Chunjiang Ge, Jiaxin Chen, Qimai Li, Weihan Shen, \textbf{Xiaolong Zhu}, Xiu Li. ``Using Human Feedback to Fine-tune Diffusion Models without Any Reward Model." \emph{IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 2024.

    \item[15.]Enhong Liu, Joseph Suarez, Chenhui You, Bo Wu, Bingcheng Chen, Jun Hu, Jiaxin Chen, \textbf{Xiaolong Zhu}, Clare Zhu, Julian Togelius, Sharada Mohanty, Weijun Hong, Rui Du, Yibing Zhang, Qinwen Wang, Xinhang Li, Zheng Yuan, Xiang Li, Yuejia Huang, Kun Zhang, Hanhui Yang, Shiqi Tang, Phillip Isola. ``The NeurIPS 2022 Neural MMO Challenge: A Massively Multiagent Competition with Specialization and Trade." \emph{NeurIPS 2022 Competitions Track}, 2023.
  
    \item[14.]Yangkun Chen, Joseph Suarez, Junjie Zhang, Chenghui Yu, Bo Wu, Hanmo Chen, Hengman Zhu, Rui Du, Shanliang Qian, Shuai Liu, Weijun Hong, Jinke He, Yibing Zhang, Liang Zhao, Clare Zhu, Julian Togelius, Sharada Mohanty, Jiaxin Chen, Xiu Li, \textbf{Xiaolong Zhu}, Phillip Isola. ``Benchmarking Robustness and Generalization in Multi-Agent Systems: A Case Study on Neural MMO." \emph{International Conference on Autonomous Agents and Multiagent Systems (AAMAS)}, 2023.

    \item[13.]Hanmo Chen, Stone Tao, Jiaxin Chen, Weihan Shen, Xihui Li, Chenghui Yu, Sikai Cheng, \textbf{Xiaolong Zhu}, Xiu Li. ``Emergent Collective Intelligence from Massive-agent Cooperation and Competition." \emph{NeurIPS 2022 Deep RL Workshop}, 2023.
  
    \item[12.]Yuhao Jiang, Kunjie Zhang, Qimai Li, Jiaxin Chen, \textbf{Xiaolong Zhu}. ``Multi-Agent Path Finding via Tree LSTM." \emph{AAAI 2023 MAPF Workshop}, 2022.
  
    \item[11.]Rongqin Liang, Yuanheng Zhu, Zhentao Tang, Mu Yang, \textbf{Xiaolong Zhu}. ``Proximal Policy Optimization with Elo-based Opponent Selection and Combination with Enhanced Rolling Horizon Evolution Algorithm." \emph{IEEE Conference on Games (CoG)}, 2021.

    \item[10.] Haozhi Huang, Hao Wang, Wenhan Luo, Lin Ma, Wenhao Jiang, \textbf{Xiaolong Zhu}, Zhifeng Li, and Wei Liu. ``Real-Time Neural Style Transfer for Videos." \emph{IEEE Conference on Computer Vision and Pattern Recognition (CVPR)}, 2017.

  \item[9.] \textbf{Xiaolong Zhu}, Wei Liu, Xuhui Jia and Kwan-Yee K. Wong. ``A Two-Stage Detector for Hand Detection in Ego-Centric Videos." \emph{Winter Conference on Applications of Computer Vision (WACV)}, 2016.
  
  \item[8.] Xuhui Jia, Heng Yang, \textbf{Xiaolong Zhu}, Zhanghui Kuang, Yifeng Niu, Kwok-Ping Chan. ``Reflective Regression of 2D-3D Face Shape Across Large Pose." \emph{The British Machine Vision Conference (BMVC)}, 2016.

  \item[7.] \textbf{Xiaolong Zhu}, Xuhui Jia and Kwan-Yee K. Wong. ``Pixel-Level Hand Detection with Shape-aware Structured Forests." \emph{Asian Conference on Computer Vision (ACCV)}, 2014.

  \item[6.] \textbf{Xiaolong Zhu}, Ruoxin Sang, Xuhui Jia and Kwan-Yee K. Wong. ``A Hand Shape Recognizer from Simple Sketches." \emph{International Conference on Image and Vision Computing New Zealand (IVCNZ)}, 2013.

  \item[5.] Xuhui Jia, \textbf{Xiaolong Zhu}, Angran Lin and Kwok-Ping Chan. ``Face Alignment using Structured Random Regressors Combined with Statistical Shape Model Fitting." \emph{International Conference on Image and Vision Computing New Zealand (IVCNZ)}, 2013.

  \item[4.] \textbf{Xiaolong Zhu}, Kwan-Yee K. Wong. ``Single-Frame Hand Gesture Recognition Using Color and Depth Kernel Descriptors." \emph{IEEE International Conference on Pattern Recognition (ICPR)}, 2012.

  \item[3.] Zhihu Chen, Kwan-Yee K. Wong, Yasuyuki Matsushita, \textbf{Xiaolong Zhu}, Miaomiao Liu. ``Self-Calibrating Depth from Refraction." \emph{IEEE International Conference on Computer Vision (ICCV)}, 2011.

  \item[2.] \textbf{Xiaolong Zhu}, Huijing Zhao, Yiming Liu, Yipu Zhao, Hongbin Zha. ``Segmentation and Classification of Range Image from an Intelligent Vehicle in Urban Environment." \emph{IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)}, 2010.
  %doi:10.1109/IROS.2010.5652703

  \item[1.] Huijing Zhao, Yiming Liu,\textbf{ Xiaolong Zhu}, Yipu Zhao, Hongbin Zha. ``Scene Understanding in a Large Dynamic Environment through a Laser-based Sensing." \emph{IEEE International Conference on Robotics and Automation (ICRA)}, 2010.
  %doi:10.1109/ROBOT.2010.5509169

\end{bibsection}

[Journal Papers]

\begin{bibsection}
    \item[1.] \textbf{Xiaolong Zhu}, Xuhui Jia, Kwan-Yee K. Wong. Structured Forests for Pixel-level Hand Detection and Hand Part Labelling. \emph{Computer Vision and Image Understanding (CVIU)}, 2015.

    \item[2.] Zhihu Chen, Kwan-Yee K. Wong, Yasuyuki Matsushita, \textbf{Xiaolong Zhu}. Depth from Refraction Using a Transparent Medium with Unknown Pose and Refractive Index. \emph{International Journal of Computer Vision (IJCV)}, 2012.

\end{bibsection}



%----------------------------------------------------------------------------------------
%	Patents List
%----------------------------------------------------------------------------------------

\section{Patents}
[In English]

\begin{bibsection}
  \item[1.] Method and apparatus for training gaze tracking model, and method and apparatus for gaze tracking. US-11797084-B2
  \item[2.] Facial expression synthesis method and apparatus, electronic device, and storage medium. US-11030439-B2
  \item[3.] Method and apparatus for training neural network model used for image processing, and storage medium. US-2019228264-A1
  \item[4.] Method and apparatus for recognizing postures of multiple persons, electronic device, and storage medium. EP-3876140-B1
  \item[5.] Method and apparatus for training pose recognition model, and method and apparatus for image recognition. US-11907848-B2
  \item[6.] Augmented reality processing method, object recognition method, and related apparatus. EP-3617995-A1
  \item[7.] Story monitoring method when robot takes elevator, electronic device, and computer storage medium. US-11242219-B2
  \item[8.] Method and apparatus for generating music. US-11301641-B2
  \item[9.] Action recognition method and apparatus, and human-machine interaction method and apparatus. US-11710351-B2
  \item[10.] Camera orientation tracking method and apparatus, device, and system. EP-3798983-B1
  \item[11.] Neural network model deployment method, prediction method, and apparatus. EP-3614316-A1
  \item[12.] Video data processing method and apparatus, and storage medium. US-11461876-B2
  \item[13.] Video image processing method and apparatus. US-10880458-B2
  \item[14.] Image recognition method and apparatus, electronic device, and readable storage medium using an update on body extraction parameter and alignment parameter. US-11417095-B2
  \item[15.] Foreground data generation method and method for applying same, related apparatus, and system. US-2021279888-A1
  \item[16.] Image processing method and apparatus. US-11200680-B2
  \item[17.] Method and apparatus for training gaze tracking model, and method and apparatus for gaze tracking. US-11797084-B2
  \item[18.] Facial expression synthesis method and apparatus, electronic device, and storage medium. US-11030439-B2
  \item[19.] Method and apparatus for training neural network model used for image processing, and storage medium. US-2019228264-A1
  \item[20.] Method and apparatus for recognizing postures of multiple persons, electronic device, and storage medium. EP-3876140-B1
  \item[21.] Method and apparatus for training pose recognition model, and method and apparatus for image recognition. US-11907848-B2
  \item[22.] Augmented reality processing method, object recognition method, and related apparatus. EP-3617995-A1
  \item[23.] Story monitoring method when robot takes elevator, electronic device, and computer storage medium. US-11242219-B2
  \item[24.] Method and apparatus for generating music. US-11301641-B2
  \item[25.] Action recognition method and apparatus, and human-machine interaction method and apparatus. US-11710351-B2
  \item[26.] Camera orientation tracking method and apparatus, device, and system. EP-3798983-B1
  \item[27.] Neural network model deployment method, prediction method, and apparatus. EP-3614316-A1
  \item[28.] Video data processing method and apparatus, and storage medium. US-11461876-B2
  \item[29.] Video image processing method and apparatus. US-10880458-B2
  \item[30.] Image recognition method and apparatus, electronic device, and readable storage medium using an update on body extraction parameter and alignment parameter. US-11417095-B2
  \item[31.] Foreground data generation method and method for applying same, related apparatus, and system. US-2021279888-A1
  \item[32.] Image processing method and apparatus. US-11200680-B2
  \item[33.] Control method and device for interactive task, storage medium and computer equipment. CN-110639208-B
  \item[34.] Model training method, model calling equipment and readable storage medium. CN-110782004-B
  \item[35.] Model training method, model using method, computer device, and storage medium. CN-111841018-B
  \item[36.] Interaction model training method, device, computer equipment and storage medium. CN-113509726-B
  \item[37.] Data sampling method and device, computer equipment and storage medium. CN-113032621-A
  \item[38.] Intelligent agent control method and device, computer equipment and storage medium. CN-112905013-A
  \item[39.] Level setting method and device, computer equipment and storage medium. CN-113134238-A
  \item[40.] Modeling method and device of intelligent agent, equipment and storage medium. CN-115645910-A
  \item[41.] Game behavior planning method, device, equipment and storage medium. CN-115624759-A
  \item[42.] Model training method, action strategy making method, server and storage medium. CN-115944924-A
  \item[43.] Video frame data sampling method and device, computer equipment and storage medium. CN-112925949-A
  \item[44.] Virtual object control method, virtual object control device, virtual object model training method, virtual object model training device and computer equipment. CN-112933605-A
  \item[45.] Intelligent agent training method, computer equipment and storage medium. CN-115759284-A
  \item[46.] Feature analysis method, device, computer equipment and storage medium. CN-113139447-B
\end{bibsection}


\end{document}



%%%%%%%%%%%%%%%%%%%%%%%%%% End CV Document %%%%%%%%%%%%%%%%%%%%%%%%%%%%%
